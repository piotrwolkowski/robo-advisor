{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9743493, 0.0256507])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "p = np.array([0.6, 0.4])\n",
    "sigma = np.array([[0.0287, 0], [0, 0.0017]])\n",
    "p_var = p @ sigma @ p\n",
    "risk_contribs = np.diag(p) @ sigma @ p / (p @ sigma @ p)\n",
    "risk_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb = 4.0\n",
    "gamma = 0.3\n",
    "sigma = np.array([[0.0287, 0], [0, 0.0017]])\n",
    "mu = gamma * np.sqrt(np.diag(sigma))\n",
    " \n",
    "w_star = 1.0 / lamb * np.matrix(sigma).I @ mu\n",
    "w_star = np.asarray(w_star).flatten()\n",
    " \n",
    "w_var = w_star @ sigma @ w_star     \n",
    "risk_contribs = np.diag(w_star) @ sigma @ w_star / w_var\n",
    "risk_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.33333644, 0.33333653, 0.33332703]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Risk parity on 3 asset portfolio\n",
    "\n",
    "# Each asset contributes the same risk.\n",
    "\n",
    "import cvxpy as cp\n",
    "sigma = np.matrix([[0.0225 , 0.0216 , 0.00075],   \n",
    "                   [0.0216 , 0.0324 , 0.00045], \n",
    "                   [0.00075, 0.00045, 0.0025]])\n",
    "N = sigma.shape[0]\n",
    "w = cp.Variable(N)\n",
    "gamma = 1.0\n",
    "objective = cp.Minimize(0.5 * cp.quad_form(w, sigma) - gamma * sum(cp.log(w)))\n",
    "constraints = []    \n",
    "prob = cp.Problem(objective, constraints)\n",
    "result = prob.solve()\n",
    "p = w.value\n",
    "risk_contribs = np.diag(p) @ sigma @ p / (p @ sigma @ p)\n",
    "risk_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  8 of 8 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.08333344, 0.08333475, 0.08333488, 0.08333518, 0.11110997,\n",
       "         0.11111147, 0.11111327, 0.33332705]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each asset class contributes the same risk.\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "tickers = ['VV', 'VB', 'VEA', 'VWO', 'AGG', 'BNDX', 'EMB', 'DJP']\n",
    "rets = yf.download(tickers, start='2014-01-01', end='2021-12-31')['Adj Close']\n",
    "rets = rets.pct_change().dropna(axis=0, how='any')[tickers]\n",
    "sigma = np.matrix(rets.cov().values) * 252 # the annualized covariance matrix of the returns\n",
    "\n",
    "N = sigma.shape[0]\n",
    "w = cp.Variable(N)\n",
    "\n",
    "# The constrcutction of the gamma can be dynamic and based on the structure of the investment potfolio.\n",
    "# If an asset class is represented by ùëö instruments in the strategy, then each instrument gets a weight (or ùõæùëñ value) of 1/ùëö.\n",
    "gamma = np.concatenate((np.ones(4) / 4, np.ones(3) / 3, np.ones(1) / 1)) # A vector of risk aversion coefficients. Optimization function uses it to calculate risk allocation.\n",
    "\n",
    "# Below, weights close to zero are penalized. The log of small numbers is negative and larger the closer to zero is the number.\n",
    "# The function is minimizing, so subtracting large, negative numbers results in larger outcome.\n",
    "# Since there are different numbers of assets, the gamma values will scale the logarithmic penalties differently.\n",
    "objective = cp.Minimize(0.5 * cp.quad_form(w, sigma) - (gamma @ cp.log(w)))\n",
    "constraints = []\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "result = prob.solve()\n",
    "p = w.value\n",
    "p_var = p @ sigma @ p\n",
    "risk_contribs = np.diag(p) @ sigma @ p / (p @ sigma @ p)\n",
    "risk_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  8 of 8 completed\n",
      "/tmp/ipykernel_2156/2991577874.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  d_bar[i][j] = np.linalg.norm(dist[i] - dist[j])\n"
     ]
    }
   ],
   "source": [
    "# Similarities Distance between different assets\n",
    "# The smaller the value in the resulting matrix, the assets have more similar correlations to other assets.\n",
    "import itertools\n",
    " \n",
    "tickers = ['VV', 'VB', 'AGG', 'VEA', 'BNDX', 'VWO', 'EMB', 'DJP']            \n",
    "rets = yf.download(tickers, start='2014-01-01', end='2021-12-31')['Adj Close']\n",
    "rets = rets.pct_change().dropna(axis=0, how='any')[tickers]\n",
    "cov, corr = rets.cov() * 252, rets.corr()\n",
    " \n",
    "dist = ((1 - corr) / 2.) ** .5\n",
    " \n",
    "d_bar = dist * 0\n",
    "for i, j in itertools.permutations(dist.columns, 2):\n",
    "    d_bar[i][j] = np.linalg.norm(dist[i] - dist[j])\n",
    "round(d_bar, 4)\n",
    "\n",
    "d_bar_copy = d_bar.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.29511752,  2.        ],\n",
       "       [ 3.        ,  8.        ,  0.36912843,  3.        ],\n",
       "       [ 5.        ,  9.        ,  0.40906408,  4.        ],\n",
       "       [ 2.        ,  4.        ,  0.60430202,  2.        ],\n",
       "       [ 6.        , 10.        ,  0.7038704 ,  5.        ],\n",
       "       [ 7.        , 12.        ,  0.83002941,  6.        ],\n",
       "       [11.        , 13.        ,  0.90802624,  8.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Find the smallest non-diagonal entry of . Assume ùëñ and ùëó give the labels of this minimum value.\n",
    "# 2. Create a new cluster out of clusters ùëñ and ùëó.\n",
    "# 3. Calculate the distance of every asset other than ùëñ and ùëó to the new cluster. The distance for a particular cluster is defined as the minimum of the distance to cluster ùëñ and the distance to cluster ùëó.\n",
    "# 4. Update . This consists of two steps:\n",
    "# 4a. First, remove the rows and columns corresponding to ùëñ and ùëó.\n",
    "# 4b. Then, augment  by adding a row and a column with the distances from the new cluster to each existing cluster\n",
    "\n",
    "d_bar = d_bar_copy.copy()\n",
    "\n",
    "import pandas as pd\n",
    "n = d_bar.shape[0]\n",
    "link_mat = np.zeros((n-1, 4))\n",
    "cluster_sizes = {_: 1 for _ in d_bar.columns}\n",
    "cluster_indices = dict(zip(d_bar.columns, range(n)))\n",
    " \n",
    "for it in range(n - 1):\n",
    "    col_names = d_bar.columns\n",
    "    idx = np.tril_indices(d_bar.shape[0], -1)\n",
    "    min_idx = np.argmin(d_bar.values[idx])\n",
    "    i_int, j_int = idx[1][min_idx], idx[0][min_idx]\n",
    "    i, j = col_names[i_int], col_names[j_int]\n",
    "    min_val = d_bar[i][j]\n",
    " \n",
    "    new_name = f\"({i}, {j})\"\n",
    "    new_col = d_bar[[i, j]].min(axis=1)\n",
    "    d_bar[new_name] = new_col\n",
    "    new_col[new_name] = 0\n",
    "    #d_bar = d_bar.append(pd.DataFrame({new_name: new_col}).T) # obsolete and remvoed from pandas 2.0\n",
    "    d_bar = pd.concat([d_bar, pd.DataFrame({new_name: new_col}).T])\n",
    "\n",
    "    d_bar.drop([i, j], axis=0, inplace=True)\n",
    "    d_bar.drop([i, j], axis=1, inplace=True)\n",
    " \n",
    "    cluster_sizes[new_name] = cluster_sizes[i] + cluster_sizes[j]\n",
    "    cluster_indices[new_name] = n + it\n",
    "    link_mat[it, :] = [cluster_indices[i], cluster_indices[j],\n",
    "                       min_val, cluster_sizes[new_name]]\n",
    "\n",
    "link_mat\n",
    "\n",
    "# scipy contains an algorithm that performs the **hierarchical clustering** but in a more efficient manner:\n",
    "\n",
    "# import scipy.cluster.hierarchy as sch\n",
    "# link_mat = sch.linkage(d_bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
